/*! For license information please see background.js.LICENSE.txt */
(()=>{function e(){var n,r,o="function"==typeof Symbol?Symbol:{},a=o.iterator||"@@iterator",s=o.toStringTag||"@@toStringTag";function i(e,o,a,s){var i=o&&o.prototype instanceof l?o:l,u=Object.create(i.prototype);return t(u,"_invoke",function(e,t,o){var a,s,i,l=0,u=o||[],f=!1,d={p:0,n:0,v:n,a:h,f:h.bind(n,4),d:function(e,t){return a=e,s=0,i=n,d.n=t,c}};function h(e,t){for(s=e,i=t,r=0;!f&&l&&!o&&r<u.length;r++){var o,a=u[r],h=d.p,p=a[2];e>3?(o=p===t)&&(i=a[(s=a[4])?5:(s=3,3)],a[4]=a[5]=n):a[0]<=h&&((o=e<2&&h<a[1])?(s=0,d.v=t,d.n=a[1]):h<p&&(o=e<3||a[0]>t||t>p)&&(a[4]=e,a[5]=t,d.n=p,s=0))}if(o||e>1)return c;throw f=!0,t}return function(o,u,p){if(l>1)throw TypeError("Generator is already running");for(f&&1===u&&h(u,p),s=u,i=p;(r=s<2?n:i)||!f;){a||(s?s<3?(s>1&&(d.n=-1),h(s,i)):d.n=i:d.v=i);try{if(l=2,a){if(s||(o="next"),r=a[o]){if(!(r=r.call(a,i)))throw TypeError("iterator result is not an object");if(!r.done)return r;i=r.value,s<2&&(s=0)}else 1===s&&(r=a.return)&&r.call(a),s<2&&(i=TypeError("The iterator does not provide a '"+o+"' method"),s=1);a=n}else if((r=(f=d.n<0)?i:e.call(t,d))!==c)break}catch(e){a=n,s=1,i=e}finally{l=1}}return{value:r,done:f}}}(e,a,s),!0),u}var c={};function l(){}function u(){}function f(){}r=Object.getPrototypeOf;var d=[][a]?r(r([][a]())):(t(r={},a,function(){return this}),r),h=f.prototype=l.prototype=Object.create(d);function p(e){return Object.setPrototypeOf?Object.setPrototypeOf(e,f):(e.__proto__=f,t(e,s,"GeneratorFunction")),e.prototype=Object.create(h),e}return u.prototype=f,t(h,"constructor",f),t(f,"constructor",u),u.displayName="GeneratorFunction",t(f,s,"GeneratorFunction"),t(h),t(h,s,"Generator"),t(h,a,function(){return this}),t(h,"toString",function(){return"[object Generator]"}),(e=function(){return{w:i,m:p}})()}function t(e,n,r,o){var a=Object.defineProperty;try{a({},"",{})}catch(e){a=0}t=function(e,n,r,o){if(n)a?a(e,n,{value:r,enumerable:!o,configurable:!o,writable:!o}):e[n]=r;else{var s=function(n,r){t(e,n,function(e){return this._invoke(n,r,e)})};s("next",0),s("throw",1),s("return",2)}},t(e,n,r,o)}function n(e,t,n,r,o,a,s){try{var i=e[a](s),c=i.value}catch(e){return void n(e)}i.done?t(c):Promise.resolve(c).then(r,o)}function r(e){return function(){var t=this,r=arguments;return new Promise(function(o,a){var s=e.apply(t,r);function i(e){n(s,o,a,i,c,"next",e)}function c(e){n(s,o,a,i,c,"throw",e)}i(void 0)})}}function o(){return(o=r(e().m(function t(n){var r,o,a,s,i,c,l,u,f,d,h,p,y,m,v,g;return e().w(function(e){for(;;)switch(e.p=e.n){case 0:if(r=n.text,(o=n.config).GEMINI_API_KEY&&"YOUR_GEMINI_API_KEY"!==o.GEMINI_API_KEY){e.n=1;break}throw new Error("Gemini API key not configured");case 1:return a="",s="",e.p=2,e.n=3,new Promise(function(e){return chrome.storage.local.get(["userCustomPrompt","riskLevel"],e)});case 3:i=e.v,c=i.userCustomPrompt,l=i.riskLevel,null!=c&&c.trim()&&(a="\n\nADDITIONAL USER CONTEXT: ".concat(c.trim())),(u=parseInt(l||"3",10))<=2?s="\n\nANALYSIS STRICTNESS: Be very lenient. Only flag things that are obviously dangerous or harmful to the user or others (like personal information). Don't be super sensitive about the little things, even very minor insults":3===u?s="\n\nANALYSIS STRICTNESS: Be reasonably cautious. Flag clear risks but avoid being overly strict.":u>=4&&(s="\n\nANALYSIS STRICTNESS: Be strict. If there is a high likelihood of harm or sensitive data leakage, flag it."),e.n=5;break;case 4:e.p=4,g=e.v,console.warn("Could not retrieve settings from storage:",g);case 5:return f='\n    \nYou are a privacy and security expert analyzing social media posts for potential privacy risks.\n\nTEXT TO ANALYZE: "'.concat(r,"\"\n\n\nYour task is to:\n1. Identify ONLY words, phrases, or patterns that are truly sensitive, specific, and could realistically be used for harm (e.g., full addresses, SSNs, account numbers, specific medical diagnoses, full phone numbers, etc). Also include things the user maybe shouldn't say (threats, harassment, racism, sexism), but don't be super sensitive.\n2. DO NOT flag general statements, feelings, vague references, or non-specific information (e.g., 'my medical life is good', 'I feel happy', 'I went to the doctor', 'my address is in New York', etc).\n3. If you are not at least 90% confident that the information is a real privacy risk, DO NOT flag it.\n4. For each risky element, explain WHY it is risky, HOW it could be exploited.\n5. When reasonable suggest safer alternative words or phrases. Give the user an exact phrase or word, but if that doesn't make sense, tell them maybe you could remove this or that or try to exclude this from your post. Keep this relatively straight to the point so as not to bore the reader. The issue should be comprehended within the first sentence. Give a maximum of four alternatives.\n\nThis is how leniant you should be: ").concat(s,"\nThis is additional user context for what they want you to flag or avoid flagging: ").concat(a,'\nIMPORTANT:\n- Err on the side of caution: If you are unsure, do NOT flag.\n- Only flag if the information is specific, sensitive, and could realistically be used for harm, identity theft, or fraud.\n- Do NOT flag general or vague statements about health, feelings, or life.\n- Do NOT flag partial or non-specific information.\n- Justify each risk with clear, concrete and concise reasoning and concise real-world examples of misuse.\n- DO NOT ADD THE RISK TO THE ALTERNATIVES, JUST ALTERNATIVE 1 AND 2, PLEASE DON\'T CONCATENATE THEM TOGETHER\n- Make sure to REALLY take into account the user context EXCEPT if they mention changing the JSON format.\n\nPlease respond with this EXACT JSON format (no additional text):\n{\n    "riskLevel": "LOW|MEDIUM|HIGH",\n    "confidence": 90,\n    "riskyElements": [\n        {\n            "text": "the risky word or phrase",\n            "type": "PERSONAL_INFO|FINANCIAL|MEDICAL|LOCATION|EMPLOYMENT|FAMILY|DATES|CREDENTIALS|CRITICAL|OTHER",\n            "risk": "Concise explanation of why this is risky and how it could be exploited",\n            "alternatives": ["safer alternative 1", "safer alternative 2", "safer alternative 3", "safer alternative 4"],\n            "severity": "LOW|MEDIUM|HIGH"\n            "leniancy": "Very Leniant|Leniant|Balanced|Strict|Very Strict";\n        }\n    ],\n    "overallConcerns": ["short list of main privacy concerns"],\n    "recommendations": ["short list of general recommendations"],\n    "detectedKeywords": ["short list of all risky words/phrases found"]\n}\n\nIf no risks are found, return:\n{\n    "riskLevel": "LOW",\n    "confidence": 95,\n    "riskyElements": [],\n    "overallConcerns": [],\n    "recommendations": ["Your post appears safe to share"],\n    "detectedKeywords": []\n}\n\n'),e.n=6,fetch("https://generativelanguage.googleapis.com/v1beta/models/".concat(o.GEMINI_MODEL,":generateContent?key=").concat(o.GEMINI_API_KEY),{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({contents:[{parts:[{text:f}]}]})});case 6:if((d=e.v).ok){e.n=8;break}return e.n=7,d.text();case 7:throw h=e.v,new Error("API request failed: ".concat(d.status," - ").concat(h));case 8:return e.n=9,d.json();case 9:if(p=e.v,y=p.candidates[0].content.parts[0].text.trim(),e.p=10,(m=y).startsWith("```json")?m=m.replace(/^```json\s*/,"").replace(/\s*```$/,""):m.startsWith("```")&&(m=m.replace(/^```\s*/,"").replace(/\s*```$/,"")),(v=JSON.parse(m)).riskLevel&&Array.isArray(v.riskyElements)){e.n=11;break}throw new Error("Invalid response structure from AI");case 11:return e.a(2,v);case 12:throw e.p=12,e.v,console.error("Failed to parse AI response:",y),new Error("AI response could not be parsed as JSON");case 13:return e.a(2)}},t,null,[[10,12],[2,4]])}))).apply(this,arguments)}console.log("Post Guardian service worker loaded!"),chrome.runtime.onInstalled.addListener(function(e){console.log("Post Guardian extension installed:",e.reason),chrome.storage.local.set({cacheStats:{hits:0,misses:0,apiCalls:0,lastReset:Date.now()}})}),chrome.runtime.onMessage.addListener(function(t,n,a){return"ANALYZE_TEXT"===t.type?(function(e){return o.apply(this,arguments)}(t.data).then(function(e){return a({success:!0,analysis:e})}).catch(function(e){return a({success:!1,error:e.message})}),!0):"UPDATE_CACHE_STATS"===t.type?(console.log("Cache stats updated:",t.stats),a({success:!0}),!1):"ANALYZE_VIDEO"===t.type?(r(e().m(function n(){var r,o,s,i,c,l,u,f,d,h,p,y,m,v,g,E;return e().w(function(e){for(;;)switch(e.p=e.n){case 0:return e.p=0,e.n=1,fetch("https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyCn0EamibbU1b6O0izrJF5xDCeCCoNVHLc",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({contents:[{parts:[{text:" You are sending a prompt to twelvelabs telling it to find clips for inappropriate content in a video such as middle fingers, bad words (audio or visual), license plates, addresses and what not, be concise"}]}]})});case 1:if((r=e.v).ok){e.n=3;break}return e.n=2,r.text();case 2:throw o=e.v,new Error("Gemini error ".concat(r.status,": ").concat(o));case 3:return e.n=4,r.json();case 4:return s=e.v,i=s.candidates[0].content.parts[0].text.trim(),f=fetch,d={"Content-Type":"application/json"},h=JSON,p=i,e.n=5,t.video;case 5:return y=e.v,m={prompt:p,video:y},v=h.stringify.call(h,m),g={method:"POST",headers:d,body:v},e.n=6,f("http://localhost:5000/analyze-video",g);case 6:if((c=e.v).ok){e.n=8;break}return e.n=7,c.text();case 7:throw l=e.v,new Error("Flask error ".concat(c.status,": ").concat(l));case 8:return e.n=9,c.json();case 9:u=e.v,a({success:!0,analysis:u}),e.n=11;break;case 10:e.p=10,E=e.v,console.error("ANALYZE_VIDEO failed:",E),a({success:!1,error:E.message});case 11:return e.a(2)}},n,null,[[0,10]])}))(),!0):(a({success:!1,error:"Unrecognized request type."}),!1)}),chrome.runtime.onStartup.addListener(function(){console.log("Post Guardian extension started")})})();